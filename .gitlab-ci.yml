image: python:3.7

stages:
    - test
    - docs
    - publish
    - publish_test

# unit tests: python 3.x (preferred)
test_unit:
    stage: test
    script:
        # install packages
        - pip3 install -r requirements.txt
        - pip3 install .
        # run unit tests
        - make unit_test
        # run linter
        - make lint
    tags:
        - cm-official-docker-executor

# unit tests: python 2.x
test_unit_python_2_x:
    image: python:2.7
    stage: test
    script:
        # install packages
        - pip install -r requirements.txt
        - pip install .
        # run unit tests
        - make unit_test
    tags:
        - cm-official-docker-executor

# generate code coverage docs
docs_code_coverage:
    stage: docs
    script:
        # install packages
        - pip3 install -r requirements.txt
        - pip3 install .
        # generate coverage
        - make coverage
    tags:
        - cm-official-docker-executor
    artifacts:
        name: ${CI_COMMIT_REF_NAME}_code_coverage
        paths:
            - code_coverage
        expire_in: 1 month

# generate code docs
docs_code:
    stage: docs
    script:
        # install packages
        - pip3 install -r requirements.txt
        - pip3 install .
        # install apt packages: doxygen
        - apt-get update
        - apt-get install -y doxygen
        # generate docs
        - make code_docs
    tags:
        - cm-official-docker-executor
    artifacts:
        name: ${CI_COMMIT_REF_NAME}_code_docs
        paths:
            - code_docs
        expire_in: 1 month

# Publish to internal artifactory
# Note: Will build and push eggs when new tags are pushed with the assumption being the package
# version has been updated. However even if it hasn't it will simply update the existing version
publish_egg_to_artifactory:
    stage: publish
    # for now publish on develop and master as well (instead of just tags)
    only:
        - tags
        - master
        - develop
    tags:
        - docker-executor
    script:
        - make build
        - EGG_FILE=$(ls dist/*.gz)
        - EGG_NAME=$(basename $EGG_FILE)
        - URL=${ARTIFACTORY_BASE_URL}/f5-cloud-solutions-pypi/f5-cloud-sdk/${EGG_NAME}
        - echo ${URL}
        - >-
          UPLOAD_RESULT=$(curl -H "Authorization: Bearer ${ARTIFACTORY_TOKEN}" -X PUT --data-binary @${EGG_FILE} ${URL})
        - if [[ $? -eq 0 ]] && [[ "$UPLOAD_RESULT" == *created* ]]; then echo "Upload complete"; else echo "Upload failed"; exit 1; fi
        - echo $UPLOAD_RESULT

# publish docs to internal pages: - this job MUST be named 'pages'
pages:
    stage: publish
    environment:
        name: staging
        url: https://${CI_PROJECT_NAMESPACE}.${PAGES_DOMAIN}/${CI_PROJECT_NAME}
    tags:
        - cm-official-docker-executor
    script:
        - PUBLIC_DIR='./public'
        - mkdir -p ${PUBLIC_DIR}
        # place index.html in public dir
        - cp docs/index.html ${PUBLIC_DIR}/index.html
        # place code coverage artifacts under /coverage
        - mkdir -p ${PUBLIC_DIR}/coverage
        - cp -R code_coverage/* ${PUBLIC_DIR}/coverage
        # place code docs artifacts under /code-docs
        - mkdir -p ${PUBLIC_DIR}/code-docs
        - cp -R code_docs/html/* ./public/code-docs
        # etc...
    artifacts:
        paths:
            - public

# publish test: test internal (artifactory) install
publish_test_internal_install:
    stage: publish_test
    script:
        # install packages - verbose for debug
        - pip3 install f5-cloud-sdk --extra-index-url ${ARTIFACTORY_BASE_URL}/api/pypi/f5-cloud-solutions-pypi/simple
    tags:
        - cm-official-docker-executor